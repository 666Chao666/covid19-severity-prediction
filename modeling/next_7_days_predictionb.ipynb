{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../') \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sklearn\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "# from viz import viz\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file, save\n",
    "from functions import merge_data\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import load_data\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import fit_and_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading county level data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/hrsa/data_AHRF_2018-2019/processed/df_renamed.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;31m# We want to silencce any warnings about, e.g. moved modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/hrsa/data_AHRF_2018-2019/processed/df_renamed.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 171\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/hrsa/data_AHRF_2018-2019/processed/df_renamed.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 175\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/hrsa/data_AHRF_2018-2019/processed/df_renamed.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;31m# We want to silencce any warnings about, e.g. moved modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/hrsa/data_AHRF_2018-2019/processed/df_renamed.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 171\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/hrsa/data_AHRF_2018-2019/processed/df_renamed.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-584061adec06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_county_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#Deaths_3/31/2020'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# outcome_cases = load_data.outcome_cases # most recent day\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# outcome_deaths = load_data.outcome_deaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimportant_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportant_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/yugroup_covid/load_data.py\u001b[0m in \u001b[0;36mload_county_level\u001b[0;34m(data_dir, cached_file, cached_file_abridged, ahrf_data, diabetes, voting, icu, heart_disease_data, stroke_data, unacast)\u001b[0m\n\u001b[1;32m     62\u001b[0m                                \u001b[0mstroke_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstroke_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                                \u001b[0mdiabetes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiabetes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                                unacast=unacast)  # also cleans usafacts data\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# basic preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/yugroup_covid/functions/merge_data.py\u001b[0m in \u001b[0;36mmerge_data\u001b[0;34m(ahrf_data, diabetes, voting, icu, heart_disease_data, stroke_data, unacast, medicare_group, resp_group)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# read in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mfacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mahrf_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mfacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfacts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Blank'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 175\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m         f, fh = _get_handle(path, 'rb',\n\u001b[1;32m    146\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minferred_compression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/hrsa/data_AHRF_2018-2019/processed/df_renamed.pkl'"
     ]
    }
   ],
   "source": [
    "df = load_data.load_county_level(data_dir = '../data/')\n",
    "df = df.sort_values('#Deaths_3/31/2020', ascending=False)\n",
    "# outcome_cases = load_data.outcome_cases # most recent day\n",
    "# outcome_deaths = load_data.outcome_deaths\n",
    "important_vars = load_data.important_keys(df)\n",
    "very_important_vars = ['PopulationDensityperSqMile2010',\n",
    "#                        'MedicareEnrollment,AgedTot2017',\n",
    "                       'PopulationEstimate2018',\n",
    "                       '#ICU_beds',\n",
    "                       'MedianAge2010',\n",
    "                       'Smokers_Percentage',\n",
    "                       'DiabetesPercentage',\n",
    "                       'HeartDiseaseMortality',\n",
    "                        '#Hospitals'\n",
    "#                        'PopMale60-642010',\n",
    "#                         'PopFmle60-642010',\n",
    "#                          'PopMale65-742010',\n",
    "#                          'PopFmle65-742010',\n",
    "#                          'PopMale75-842010',\n",
    "#                          'PopFmle75-842010',\n",
    "#                          'PopMale>842010',\n",
    "#                          'PopFmle>842010'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cases = [max(v) for v in df['cases']]\n",
    "df['max_cases'] = max_cases\n",
    "df =  df[df['max_cases'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential = {'model_type':'exponential'}\n",
    "shared_exponential = {'model_type':'shared_exponential'}\n",
    "demographics = {'model_type':'shared_exponential', 'demographic_vars':very_important_vars}\n",
    "linear = {'model_type':'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 8)),\n",
    "                                              mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=[exponential, \n",
    "                                                       shared_exponential,\n",
    "                                                       demographics,\n",
    "                                                       linear\n",
    "                                                         ],\n",
    "                                                  output_key=f'predicted_deaths_ensemble_all'\n",
    "                                                   )\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 8)),\n",
    "                                              mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=[exponential, \n",
    "                                                       shared_exponential,\n",
    "                                                       linear\n",
    "                                                         ],\n",
    "                                                  output_key=f'predicted_deaths_ensemble_no_demographics_all'\n",
    "                                                   )\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 8)),\n",
    "                                              mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=[exponential, \n",
    "                                                       shared_exponential,\n",
    "                                                       demographics\n",
    "                                                         ],\n",
    "                                                  output_key=f'predicted_deaths_ensemble_no_linear_all'\n",
    "                                                   )\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 8)),\n",
    "                                              mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=[ \n",
    "                                                       shared_exponential,\n",
    "                                                       demographics,\n",
    "                                                       linear\n",
    "                                                         ],\n",
    "                                                  output_key=f'predicted_deaths_ensemble_no_exponential_all'\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Contributions ---\n",
      "{'model_type': 'exponential'}: 0.33158405232057736\n",
      "{'model_type': 'linear'}: 0.3306937014610934\n",
      "{'model_type': 'shared_exponential'}: 0.17601947272302437\n",
      "{'model_type': 'shared_exponential', 'demographic_vars': ['PopulationDensityperSqMile2010', 'PopulationEstimate2018', '#ICU_beds', 'MedianAge2010', 'Smokers_Percentage', 'DiabetesPercentage', 'HeartDiseaseMortality', '#Hospitals']}: 0.1617027734953045\n",
      "exponential\n",
      "[{'model_type': 'shared_exponential'}, {'model_type': 'shared_exponential', 'demographic_vars': ['PopulationDensityperSqMile2010', 'PopulationEstimate2018', '#ICU_beds', 'MedianAge2010', 'Smokers_Percentage', 'DiabetesPercentage', 'HeartDiseaseMortality', '#Hospitals']}, {'model_type': 'linear'}]\n",
      "--- Model Contributions ---\n",
      "{'model_type': 'linear'}: 0.4978565953580966\n",
      "{'model_type': 'shared_exponential'}: 0.26194760915433785\n",
      "{'model_type': 'shared_exponential', 'demographic_vars': ['PopulationDensityperSqMile2010', 'PopulationEstimate2018', '#ICU_beds', 'MedianAge2010', 'Smokers_Percentage', 'DiabetesPercentage', 'HeartDiseaseMortality', '#Hospitals']}: 0.24019579548756456\n",
      "shared_exponential\n",
      "[{'model_type': 'exponential'}, {'model_type': 'shared_exponential', 'demographic_vars': ['PopulationDensityperSqMile2010', 'PopulationEstimate2018', '#ICU_beds', 'MedianAge2010', 'Smokers_Percentage', 'DiabetesPercentage', 'HeartDiseaseMortality', '#Hospitals']}, {'model_type': 'linear'}]\n",
      "--- Model Contributions ---\n",
      "{'model_type': 'exponential'}: 0.4014965228026373\n",
      "{'model_type': 'linear'}: 0.4004342596832792\n",
      "{'model_type': 'shared_exponential', 'demographic_vars': ['PopulationDensityperSqMile2010', 'PopulationEstimate2018', '#ICU_beds', 'MedianAge2010', 'Smokers_Percentage', 'DiabetesPercentage', 'HeartDiseaseMortality', '#Hospitals']}: 0.19806921751408194\n",
      "shared_exponential\n",
      "[{'model_type': 'exponential'}, {'model_type': 'shared_exponential'}, {'model_type': 'linear'}]\n",
      "--- Model Contributions ---\n",
      "{'model_type': 'exponential'}: 0.3945869591983801\n",
      "{'model_type': 'linear'}: 0.39356227581436465\n",
      "{'model_type': 'shared_exponential'}: 0.21185076498725916\n",
      "linear\n",
      "[{'model_type': 'exponential'}, {'model_type': 'shared_exponential'}, {'model_type': 'shared_exponential', 'demographic_vars': ['PopulationDensityperSqMile2010', 'PopulationEstimate2018', '#ICU_beds', 'MedianAge2010', 'Smokers_Percentage', 'DiabetesPercentage', 'HeartDiseaseMortality', '#Hospitals']}]\n",
      "--- Model Contributions ---\n",
      "{'model_type': 'exponential'}: 0.49852079632520924\n",
      "{'model_type': 'shared_exponential'}: 0.261589111816696\n",
      "{'model_type': 'shared_exponential', 'demographic_vars': ['PopulationDensityperSqMile2010', 'PopulationEstimate2018', '#ICU_beds', 'MedianAge2010', 'Smokers_Percentage', 'DiabetesPercentage', 'HeartDiseaseMortality', '#Hospitals']}: 0.23989009185809407\n"
     ]
    }
   ],
   "source": [
    "all_methods = [exponential, \n",
    "               shared_exponential,\n",
    "               demographics,\n",
    "               linear]\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 8)),\n",
    "                                              mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=all_methods,\n",
    "                                              output_key=f'predicted_deaths_ensemble_all'\n",
    "                                              )\n",
    "for (i, model) in enumerate(all_methods):\n",
    "        \n",
    "    if 'demographic_vars' in model:\n",
    "        demographic_vars = model['demographic_vars']\n",
    "    else:\n",
    "        demographic_vars = []\n",
    "    \n",
    "    method = model['model_type']\n",
    "    print(method)\n",
    "    df = fit_and_predict.fit_and_predict(df, \n",
    "                                         outcome='deaths', \n",
    "                                         method=method, \n",
    "                                         mode='predict_future', \n",
    "                                         target_day=np.array(range(1, 8)),\n",
    "                                         output_key=f'predicted_deaths_{method}_all',\n",
    "                                         demographic_vars=demographic_vars)\n",
    "    print(all_methods[0:i]+all_methods[(i+1):])\n",
    "    df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 8)),\n",
    "                                              mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=all_methods[0:i]+all_methods[(i+1):],\n",
    "                                              output_key=f'predicted_deaths_ensemble_no_{method}_all'\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_keys = [c for c in df if 'predicted' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in method_keys:\n",
    "    for d in range(1, 8):\n",
    "        newkey = key[:-3] + str(d)\n",
    "        df[newkey] = np.array([p[d-1] for p in df[key].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predicted_deaths_ensemble_all',\n",
       " 'predicted_deaths_exponential_all',\n",
       " 'predicted_deaths_ensemble_no_exponential_all',\n",
       " 'predicted_deaths_shared_exponential_all',\n",
       " 'predicted_deaths_ensemble_no_shared_exponential_all',\n",
       " 'predicted_deaths_linear_all',\n",
       " 'predicted_deaths_ensemble_no_linear_all',\n",
       " 'predicted_deaths_ensemble_1',\n",
       " 'predicted_deaths_ensemble_2',\n",
       " 'predicted_deaths_ensemble_3',\n",
       " 'predicted_deaths_ensemble_4',\n",
       " 'predicted_deaths_ensemble_5',\n",
       " 'predicted_deaths_ensemble_6',\n",
       " 'predicted_deaths_ensemble_7',\n",
       " 'predicted_deaths_exponential_1',\n",
       " 'predicted_deaths_exponential_2',\n",
       " 'predicted_deaths_exponential_3',\n",
       " 'predicted_deaths_exponential_4',\n",
       " 'predicted_deaths_exponential_5',\n",
       " 'predicted_deaths_exponential_6',\n",
       " 'predicted_deaths_exponential_7',\n",
       " 'predicted_deaths_ensemble_no_exponential_1',\n",
       " 'predicted_deaths_ensemble_no_exponential_2',\n",
       " 'predicted_deaths_ensemble_no_exponential_3',\n",
       " 'predicted_deaths_ensemble_no_exponential_4',\n",
       " 'predicted_deaths_ensemble_no_exponential_5',\n",
       " 'predicted_deaths_ensemble_no_exponential_6',\n",
       " 'predicted_deaths_ensemble_no_exponential_7',\n",
       " 'predicted_deaths_shared_exponential_1',\n",
       " 'predicted_deaths_shared_exponential_2',\n",
       " 'predicted_deaths_shared_exponential_3',\n",
       " 'predicted_deaths_shared_exponential_4',\n",
       " 'predicted_deaths_shared_exponential_5',\n",
       " 'predicted_deaths_shared_exponential_6',\n",
       " 'predicted_deaths_shared_exponential_7',\n",
       " 'predicted_deaths_ensemble_no_shared_exponential_1',\n",
       " 'predicted_deaths_ensemble_no_shared_exponential_2',\n",
       " 'predicted_deaths_ensemble_no_shared_exponential_3',\n",
       " 'predicted_deaths_ensemble_no_shared_exponential_4',\n",
       " 'predicted_deaths_ensemble_no_shared_exponential_5',\n",
       " 'predicted_deaths_ensemble_no_shared_exponential_6',\n",
       " 'predicted_deaths_ensemble_no_shared_exponential_7',\n",
       " 'predicted_deaths_linear_1',\n",
       " 'predicted_deaths_linear_2',\n",
       " 'predicted_deaths_linear_3',\n",
       " 'predicted_deaths_linear_4',\n",
       " 'predicted_deaths_linear_5',\n",
       " 'predicted_deaths_linear_6',\n",
       " 'predicted_deaths_linear_7',\n",
       " 'predicted_deaths_ensemble_no_linear_1',\n",
       " 'predicted_deaths_ensemble_no_linear_2',\n",
       " 'predicted_deaths_ensemble_no_linear_3',\n",
       " 'predicted_deaths_ensemble_no_linear_4',\n",
       " 'predicted_deaths_ensemble_no_linear_5',\n",
       " 'predicted_deaths_ensemble_no_linear_6',\n",
       " 'predicted_deaths_ensemble_no_linear_7']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in df if 'predicted' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_deaths_ensemble_all                          [450.4580874531463, 538.8713889539164, 642.662...\n",
       "predicted_deaths_exponential_all                       [470.69580158127013, 582.4838290310679, 720.82...\n",
       "predicted_deaths_ensemble_no_exponential_all           [443.9198391656373, 524.7814102219679, 617.411...\n",
       "predicted_deaths_shared_exponential_all                [459.77057973689125, 557.8093610088187, 671.72...\n",
       "predicted_deaths_ensemble_no_shared_exponential_all    [447.2881227239592, 532.4249188117444, 632.770...\n",
       "predicted_deaths_linear_all                            [420.4999999999999, 473.6999999999999, 526.899...\n",
       "predicted_deaths_ensemble_no_linear_all                [460.48979039883477, 560.694544906916, 681.426...\n",
       "predicted_deaths_ensemble_1                                                                      450.458\n",
       "predicted_deaths_ensemble_2                                                                      538.871\n",
       "predicted_deaths_ensemble_3                                                                      642.662\n",
       "predicted_deaths_ensemble_4                                                                      764.888\n",
       "predicted_deaths_ensemble_5                                                                      909.241\n",
       "predicted_deaths_ensemble_6                                                                       1080.2\n",
       "predicted_deaths_ensemble_7                                                                       1283.2\n",
       "predicted_deaths_exponential_1                                                                   470.696\n",
       "predicted_deaths_exponential_2                                                                   582.484\n",
       "predicted_deaths_exponential_3                                                                   720.821\n",
       "predicted_deaths_exponential_4                                                                   892.013\n",
       "predicted_deaths_exponential_5                                                                   1103.86\n",
       "predicted_deaths_exponential_6                                                                   1366.02\n",
       "predicted_deaths_exponential_7                                                                   1690.45\n",
       "predicted_deaths_ensemble_no_exponential_1                                                        443.92\n",
       "predicted_deaths_ensemble_no_exponential_2                                                       524.781\n",
       "predicted_deaths_ensemble_no_exponential_3                                                       617.411\n",
       "predicted_deaths_ensemble_no_exponential_4                                                       723.818\n",
       "predicted_deaths_ensemble_no_exponential_5                                                       846.365\n",
       "predicted_deaths_ensemble_no_exponential_6                                                       987.855\n",
       "predicted_deaths_ensemble_no_exponential_7                                                       1151.63\n",
       "predicted_deaths_shared_exponential_1                                                            459.771\n",
       "predicted_deaths_shared_exponential_2                                                            557.809\n",
       "predicted_deaths_shared_exponential_3                                                            671.722\n",
       "predicted_deaths_shared_exponential_4                                                            803.163\n",
       "predicted_deaths_shared_exponential_5                                                            953.822\n",
       "predicted_deaths_shared_exponential_6                                                             1125.4\n",
       "predicted_deaths_shared_exponential_7                                                            1319.61\n",
       "predicted_deaths_ensemble_no_shared_exponential_1                                                447.288\n",
       "predicted_deaths_ensemble_no_shared_exponential_2                                                532.425\n",
       "predicted_deaths_ensemble_no_shared_exponential_3                                                 632.77\n",
       "predicted_deaths_ensemble_no_shared_exponential_4                                                751.859\n",
       "predicted_deaths_ensemble_no_shared_exponential_5                                                894.066\n",
       "predicted_deaths_ensemble_no_shared_exponential_6                                                1064.81\n",
       "predicted_deaths_ensemble_no_shared_exponential_7                                                1270.81\n",
       "predicted_deaths_linear_1                                                                          420.5\n",
       "predicted_deaths_linear_2                                                                          473.7\n",
       "predicted_deaths_linear_3                                                                          526.9\n",
       "predicted_deaths_linear_4                                                                          580.1\n",
       "predicted_deaths_linear_5                                                                          633.3\n",
       "predicted_deaths_linear_6                                                                          686.5\n",
       "predicted_deaths_linear_7                                                                          739.7\n",
       "predicted_deaths_ensemble_no_linear_1                                                             460.49\n",
       "predicted_deaths_ensemble_no_linear_2                                                            560.695\n",
       "predicted_deaths_ensemble_no_linear_3                                                            681.426\n",
       "predicted_deaths_ensemble_no_linear_4                                                            826.766\n",
       "predicted_deaths_ensemble_no_linear_5                                                            1001.64\n",
       "predicted_deaths_ensemble_no_linear_6                                                            1212.03\n",
       "predicted_deaths_ensemble_no_linear_7                                                             1465.2\n",
       "Name: 1841, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[c for c in df if 'predicted' in c]].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv(\"../predictions/prediction_04_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_keys = [c for c in df if 'predicted' in c]\n",
    "geo = ['countyFIPS', 'CountyNamew/StateAbbrev']\n",
    "preds_df = df[method_keys + geo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
