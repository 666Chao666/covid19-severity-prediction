import os
import sys
import inspect
currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
sys.path.append(parentdir)
sys.path.append(parentdir + '/modeling')
from os.path import join as oj
import sklearn
import copy
import numpy as np
import scipy as sp
import pandas as pd
from functions import merge_data
from sklearn.model_selection import RandomizedSearchCV
import load_data
import exponential_modeling
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
import fit_and_predict
from datetime import datetime, timedelta
NUM_DAYS_LIST = np.array(range(1, 8))
import pygsheets

def get_all_preds():
    very_important_vars = ['PopulationDensityperSqMile2010',
    #                        'MedicareEnrollment,AgedTot2017',
                           'PopulationEstimate2018',
                           '#ICU_beds',
                           'MedianAge2010',
                           'Smokers_Percentage',
                           'DiabetesPercentage',
                           'HeartDiseaseMortality',
                           'Respiratory Mortality',
                            '#Hospitals']
    exponential = {'model_type':'exponential'}
    shared_exponential = {'model_type':'shared_exponential'}
    demographics = {'model_type':'shared_exponential', 'demographic_vars':very_important_vars}
    linear = {'model_type':'linear'}

    df = load_data.load_county_level(data_dir = '../data/')
    max_cases = [max(v) for v in df['cases']]
    df['max_cases'] = max_cases
    df =  df[df['max_cases'] > 0]
    df = fit_and_predict.fit_and_predict_ensemble(df, 
                                                  target_day=NUM_DAYS_LIST,
                                                  mode='predict_future',
                                                  outcome='deaths',
                                                  methods=[exponential, shared_exponential, demographics, linear],
                                                  output_key=f'predicted_deaths_ensemble_all'
                                                  )
    df = fit_and_predict.fit_and_predict_ensemble(df, 
                                                  target_day=NUM_DAYS_LIST,
                                                  mode='predict_future',
                                                  outcome='deaths',
                                                  methods=[shared_exponential, demographics, linear],
                                                  output_key=f'predicted_deaths_ensemble_no_exponential_all'
                                                  )
    df = fit_and_predict.fit_and_predict_ensemble(df, 
                                                  target_day=NUM_DAYS_LIST,
                                                  mode='predict_future',
                                                  outcome='deaths',
                                                  methods=[shared_exponential, linear],
                                                  output_key=f'predicted_deaths_ensemble_shared_linear_all'
                                                  )
    method_keys = [c for c in df if 'predicted' in c]
    for key in method_keys:
        for d in range(1, 8):
            newkey = key[:-3] + str(d)
            df[newkey] = np.array([p[d-1] for p in df[key].values])
    geo = ['countyFIPS', 'CountyNamew/StateAbbrev']
    preds_df = df[geo + method_keys]
    return preds_df
    
    
if __name__ == '__main__':
    # get predictions
    df_preds = get_all_preds()
    
    # rewrite pred cols
    best_key = 'predicted_deaths_ensemble_all'
    vals = df_preds[best_key].values
    
    today = datetime.today().strftime("%B %d")
    for i in range(1, 8):
        day = (datetime.today() + timedelta(days=i - 1)).strftime("%B %d")
        col = [vals[j][i - 1] for j in range(vals.shape[0])]
        df_preds.insert(i + 1, f'Predicted deaths by {day}', col)
    
    
    # write to gsheets
    service_file=oj(parentdir, 'creds.json')
    FNAME = 'County-level Predictions'
    gc = pygsheets.authorize(service_file=service_file)
    sh = gc.open(FNAME)
    
    # make new ws if it doesn't exist
    titles = [wks.title for wks in sh.worksheets()]
    if not today in titles:
        sh.add_worksheet(today, index=0)
    wks = sh.worksheet_by_title(today)
    
    # write to ws
    wks.update_value('A1', "Note: this sheet is read-only (automatically generated by the data and model)")
    wks.set_dataframe(df_preds, (3, 1)) #update the first sheet with df, starting at cell B2. 